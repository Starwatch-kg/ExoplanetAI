# üöÄ ExoplanetAI - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ò–ò

## üî¨ –ü—Ä–∏–º–µ—Ä—ã API –∑–∞–ø—Ä–æ—Å–æ–≤

### 1. –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–∏–≤–æ–π –±–ª–µ—Å–∫–∞

```bash
# –ê–Ω–∞–ª–∏–∑ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ü–µ–ª–∏
curl -X POST "http://localhost:8001/api/v1/ai/analyze_lightcurve" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "target_name": "TOI-715",
    "mission": "TESS",
    "auto_detect_cadence": true,
    "adaptive_detrending": true,
    "include_uncertainty": true,
    "explain_prediction": true
  }'
```

**–û—Ç–≤–µ—Ç:**
```json
{
  "target_name": "TOI-715",
  "predicted_class": "Confirmed",
  "confidence_score": 0.87,
  "uncertainty_bounds": [0.82, 0.92],
  "transit_probability": 0.91,
  "signal_characteristics": {
    "snr_estimate": 12.4,
    "data_points": 18743,
    "time_span_days": 27.4
  },
  "feature_importance": [0.23, 0.18, 0.15, 0.12, 0.08, ...],
  "decision_reasoning": [
    "–î–ª—è –∫–ª–∞—Å—Å–∞ Confirmed: –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ - transit_depth, snr, duration",
    "–í—ã—Å–æ–∫–∞—è –≥–ª—É–±–∏–Ω–∞ —Ç—Ä–∞–Ω–∑–∏—Ç–∞ (0.8%) —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ø–ª–∞–Ω–µ—Ç—É",
    "SNR 12.4 –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
  ],
  "recommendations": [
    "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
    "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è follow-up –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
  ],
  "data_quality_metrics": {
    "photometric_precision": 0.001,
    "systematic_noise_level": 0.02,
    "data_completeness": 0.95,
    "instrumental_effects_score": 0.03
  },
  "processing_time_ms": 342.5,
  "model_version": "enhanced_v2.0"
}
```

### 2. –£–º–Ω—ã–π –ø–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç

```bash
# –ü–æ–∏—Å–∫ —Å –ò–ò —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º
curl -X POST "http://localhost:8001/api/v1/ai/smart_search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "TOI",
    "filters": {
      "confidence_min": 0.7,
      "snr_min": 5.0,
      "data_quality_min": 0.8,
      "missions": ["TESS", "Kepler"],
      "planet_types": ["confirmed", "candidate"],
      "period_range": [1.0, 100.0]
    },
    "use_ai_ranking": true,
    "max_results": 10,
    "include_similar": true
  }'
```

**–û—Ç–≤–µ—Ç:**
```json
{
  "results": [
    {
      "name": "TOI-715.01",
      "predicted_class": "Confirmed",
      "confidence_score": 0.87,
      "ai_score": 0.92,
      "signal_characteristics": {
        "snr_estimate": 12.4,
        "data_points": 18743,
        "time_span_days": 27.4
      },
      "disposition": "CONFIRMED",
      "orbital_period": 19.3,
      "planet_radius": 1.55,
      "ai_ranking_applied": true
    }
  ],
  "total_found": 156,
  "ai_ranked": true,
  "recommendations": [
    "–ù–∞–π–¥–µ–Ω–æ 45 –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç",
    "–ù–∞–π–¥–µ–Ω–æ 111 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç—ã"
  ],
  "search_time_ms": 1247.3,
  "filters_applied": {
    "confidence_min": 0.7,
    "snr_min": 5.0,
    "missions": ["TESS", "Kepler"]
  }
}
```

### 3. –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑

```bash
# –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ü–µ–ª–µ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
curl -X POST "http://localhost:8001/api/v1/ai/batch_analyze" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "targets": ["TOI-715", "Kepler-452b", "TRAPPIST-1e"],
    "analysis_params": {
      "mission": "TESS",
      "include_uncertainty": true,
      "explain_prediction": false
    },
    "parallel_limit": 3
  }'
```

## üåê –ü—Ä–∏–º–µ—Ä—ã —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### 1. React Hook –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞

```typescript
// hooks/useSmartSearch.ts
import { useState, useCallback } from 'react';

interface SearchFilters {
  confidenceMin: number;
  snrMin: number;
  dataQualityMin: number;
  missions: string[];
  planetTypes: string[];
}

interface SearchResult {
  name: string;
  predicted_class: string;
  confidence_score: number;
  ai_score: number;
}

export const useSmartSearch = () => {
  const [results, setResults] = useState<SearchResult[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string>('');

  const search = useCallback(async (query: string, filters: SearchFilters) => {
    setIsLoading(true);
    setError('');

    try {
      const response = await fetch('/api/v1/ai/smart_search', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query,
          filters,
          use_ai_ranking: true,
          max_results: 20,
          include_similar: true
        })
      });

      if (!response.ok) {
        throw new Error(`Search failed: ${response.status}`);
      }

      const data = await response.json();
      setResults(data.results);
      
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Search failed');
    } finally {
      setIsLoading(false);
    }
  }, []);

  return { results, isLoading, error, search };
};
```

### 2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π —Ñ–∞–π–ª–∞

```typescript
// components/FileAnalysis.tsx
import React, { useState } from 'react';
import { Upload, Brain } from 'lucide-react';

const FileAnalysis: React.FC = () => {
  const [file, setFile] = useState<File | null>(null);
  const [analysis, setAnalysis] = useState<any>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);

  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const uploadedFile = event.target.files?.[0];
    if (uploadedFile) {
      setFile(uploadedFile);
    }
  };

  const analyzeFile = async () => {
    if (!file) return;

    setIsAnalyzing(true);
    
    try {
      // –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
      const text = await file.text();
      const lines = text.split('\n').filter(line => line.trim());
      
      const data = lines.slice(1).map(line => {
        const values = line.split(/[,\s]+/).map(v => parseFloat(v.trim()));
        return { time: values[0], flux: values[1] };
      }).filter(row => !isNaN(row.time) && !isNaN(row.flux));

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –∞–Ω–∞–ª–∏–∑
      const response = await fetch('/api/v1/ai/analyze_lightcurve', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          time_data: data.map(d => d.time),
          flux_data: data.map(d => d.flux),
          mission: 'TESS',
          include_uncertainty: true,
          explain_prediction: true
        })
      });

      const result = await response.json();
      setAnalysis(result);
      
    } catch (error) {
      console.error('Analysis failed:', error);
    } finally {
      setIsAnalyzing(false);
    }
  };

  return (
    <div className="bg-gray-800 rounded-lg p-6">
      <h2 className="text-xl font-bold text-white mb-4 flex items-center gap-2">
        <Brain className="w-6 h-6" />
        –ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
      </h2>

      <div className="space-y-4">
        <div>
          <label className="flex flex-col items-center justify-center w-full h-32 border-2 border-gray-600 border-dashed rounded-lg cursor-pointer bg-gray-700 hover:bg-gray-600">
            <div className="flex flex-col items-center justify-center pt-5 pb-6">
              <Upload className="w-8 h-8 mb-4 text-gray-400" />
              <p className="mb-2 text-sm text-gray-400">
                <span className="font-semibold">–ù–∞–∂–º–∏—Ç–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏</span>
              </p>
              <p className="text-xs text-gray-500">CSV —Ñ–∞–π–ª—ã (–≤—Ä–µ–º—è, –ø–æ—Ç–æ–∫)</p>
            </div>
            <input type="file" accept=".csv,.txt" onChange={handleFileUpload} className="hidden" />
          </label>
        </div>

        {file && (
          <div className="text-sm text-green-400">
            ‚úì –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {file.name}
          </div>
        )}

        <button
          onClick={analyzeFile}
          disabled={!file || isAnalyzing}
          className="w-full px-4 py-2 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 text-white rounded-lg transition-colors"
        >
          {isAnalyzing ? '–ê–Ω–∞–ª–∏–∑...' : '–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å'}
        </button>

        {analysis && (
          <div className="mt-6 bg-gray-700 rounded-lg p-4">
            <h3 className="font-semibold text-white mb-2">–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞</h3>
            <div className="grid grid-cols-2 gap-4 text-sm">
              <div>
                <span className="text-gray-400">–ö–ª–∞—Å—Å:</span>
                <span className="text-white ml-2">{analysis.predicted_class}</span>
              </div>
              <div>
                <span className="text-gray-400">–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</span>
                <span className="text-white ml-2">{(analysis.confidence_score * 100).toFixed(1)}%</span>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default FileAnalysis;
```

## üêç Python SDK –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤

```python
# exoplanet_ai_sdk.py
import requests
import pandas as pd
from typing import Dict, List, Optional, Union
import numpy as np

class ExoplanetAI:
    """Python SDK –¥–ª—è ExoplanetAI API"""
    
    def __init__(self, api_url: str = "http://localhost:8001", api_key: str = None):
        self.api_url = api_url.rstrip('/')
        self.api_key = api_key
        self.session = requests.Session()
        
        if api_key:
            self.session.headers.update({'Authorization': f'Bearer {api_key}'})
    
    def analyze_target(self, 
                      target_name: str,
                      mission: str = "TESS",
                      include_uncertainty: bool = True,
                      explain_prediction: bool = True) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        
        data = {
            "target_name": target_name,
            "mission": mission,
            "auto_detect_cadence": True,
            "adaptive_detrending": True,
            "include_uncertainty": include_uncertainty,
            "explain_prediction": explain_prediction
        }
        
        response = self.session.post(f"{self.api_url}/api/v1/ai/analyze_lightcurve", json=data)
        response.raise_for_status()
        return response.json()
    
    def analyze_lightcurve(self,
                          time_data: List[float],
                          flux_data: List[float],
                          flux_err_data: Optional[List[float]] = None,
                          mission: str = "TESS") -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫—Ä–∏–≤–æ–π –±–ª–µ—Å–∫–∞ –∏–∑ –º–∞—Å—Å–∏–≤–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        
        data = {
            "time_data": time_data,
            "flux_data": flux_data,
            "flux_err_data": flux_err_data,
            "mission": mission,
            "auto_detect_cadence": True,
            "adaptive_detrending": True,
            "include_uncertainty": True,
            "explain_prediction": True
        }
        
        response = self.session.post(f"{self.api_url}/api/v1/ai/analyze_lightcurve", json=data)
        response.raise_for_status()
        return response.json()
    
    def smart_search(self,
                    query: str,
                    confidence_min: float = 0.7,
                    snr_min: float = 5.0,
                    missions: List[str] = None,
                    max_results: int = 20) -> Dict:
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç"""
        
        if missions is None:
            missions = ["TESS", "Kepler"]
        
        data = {
            "query": query,
            "filters": {
                "confidence_min": confidence_min,
                "snr_min": snr_min,
                "data_quality_min": 0.8,
                "missions": missions,
                "planet_types": ["confirmed", "candidate"]
            },
            "use_ai_ranking": True,
            "max_results": max_results,
            "include_similar": True
        }
        
        response = self.session.post(f"{self.api_url}/api/v1/ai/smart_search", json=data)
        response.raise_for_status()
        return response.json()
    
    def batch_analyze(self,
                     targets: List[str],
                     mission: str = "TESS",
                     parallel_limit: int = 5) -> Dict:
        """–ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ü–µ–ª–µ–π"""
        
        data = {
            "targets": targets,
            "analysis_params": {
                "mission": mission,
                "include_uncertainty": True,
                "explain_prediction": False
            },
            "parallel_limit": parallel_limit
        }
        
        response = self.session.post(f"{self.api_url}/api/v1/ai/batch_analyze", json=data)
        response.raise_for_status()
        return response.json()
    
    def analyze_csv_file(self, file_path: str, target_name: str = "uploaded_data") -> Dict:
        """–ê–Ω–∞–ª–∏–∑ CSV —Ñ–∞–π–ª–∞ —Å –∫—Ä–∏–≤–æ–π –±–ª–µ—Å–∫–∞"""
        
        df = pd.read_csv(file_path)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        time_col = None
        flux_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'time' in col_lower or 'bjd' in col_lower or 'mjd' in col_lower:
                time_col = col
            elif 'flux' in col_lower or 'mag' in col_lower:
                flux_col = col
        
        if time_col is None or flux_col is None:
            time_col = df.columns[0]
            flux_col = df.columns[1]
        
        return self.analyze_lightcurve(
            time_data=df[time_col].tolist(),
            flux_data=df[flux_col].tolist()
        )

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
    client = ExoplanetAI(api_url="http://localhost:8001", api_key="your_api_key")
    
    # –ê–Ω–∞–ª–∏–∑ –∏–∑–≤–µ—Å—Ç–Ω–æ–π —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç—ã
    result = client.analyze_target("TOI-715")
    print(f"–ö–ª–∞—Å—Å: {result['predicted_class']}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence_score']:.1%}")
    print(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {result['recommendations']}")
    
    # –£–º–Ω—ã–π –ø–æ–∏—Å–∫
    search_results = client.smart_search("TOI", confidence_min=0.8)
    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(search_results['results'])} –æ–±—ä–µ–∫—Ç–æ–≤")
    
    # –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    batch_results = client.batch_analyze(["TOI-715", "Kepler-452b", "TRAPPIST-1e"])
    print(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(batch_results['successful_analyses'])} –æ–±—ä–µ–∫—Ç–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
    file_result = client.analyze_csv_file("lightcurve_data.csv")
    print(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_result['predicted_class']}")
```

## üìä Jupyter Notebook –ø—Ä–∏–º–µ—Ä—ã

```python
# –ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ –≤ Jupyter Notebook
import matplotlib.pyplot as plt
import numpy as np
from exoplanet_ai_sdk import ExoplanetAI

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
client = ExoplanetAI()

# –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–∏
result = client.analyze_target("TOI-715")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
feature_names = ['Transit Depth', 'SNR', 'Duration', 'Asymmetry', 'V-shape', 
                'U-shape', 'Box-shape', 'Frequency Power', 'Data Quality', 'Noise']
importance = result['feature_importance'][:10]

axes[0, 0].barh(feature_names, importance)
axes[0, 0].set_title('Feature Importance')
axes[0, 0].set_xlabel('Importance Score')

# Pie chart —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
confidence = result['confidence_score']
uncertainty = 1 - confidence
axes[0, 1].pie([confidence, uncertainty], labels=['Confident', 'Uncertain'], 
               autopct='%1.1f%%', startangle=90)
axes[0, 1].set_title(f'Prediction Confidence\n{result["predicted_class"]}')

# –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
quality_metrics = result['data_quality_metrics']
metrics_names = list(quality_metrics.keys())
metrics_values = list(quality_metrics.values())

axes[1, 0].bar(range(len(metrics_names)), metrics_values)
axes[1, 0].set_xticks(range(len(metrics_names)))
axes[1, 0].set_xticklabels(metrics_names, rotation=45)
axes[1, 0].set_title('Data Quality Metrics')
axes[1, 0].set_ylabel('Score')

# –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–∞
signal_chars = result['signal_characteristics']
char_names = list(signal_chars.keys())
char_values = list(signal_chars.values())

axes[1, 1].bar(char_names, char_values)
axes[1, 1].set_title('Signal Characteristics')
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
print("ü§ñ AI Recommendations:")
for i, rec in enumerate(result['recommendations'], 1):
    print(f"{i}. {rec}")

print("\nüß† AI Reasoning:")
for i, reason in enumerate(result['decision_reasoning'], 1):
    print(f"{i}. {reason}")
```

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### Docker Compose –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  exoplanet-ai-backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "8001:8001"
    environment:
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://user:pass@postgres:5432/exoplanet_ai
      - NASA_API_KEY=${NASA_API_KEY}
    volumes:
      - ./backend:/app
      - ./data:/app/data
    depends_on:
      - redis
      - postgres
    command: uvicorn main:app --host 0.0.0.0 --port 8001 --reload

  exoplanet-ai-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:8001
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=exoplanet_ai
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
git clone https://github.com/your-repo/exoplanet-ai.git
cd exoplanet-ai

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env —Ñ–∞–π–ª

# –ó–∞–ø—É—Å–∫ —Å Docker Compose
docker-compose -f docker-compose.dev.yml up -d

# –ò–ª–∏ –∑–∞–ø—É—Å–∫ –≤—Ä—É—á–Ω—É—é
cd backend
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8001 --reload

cd ../frontend
npm install
npm run dev
```

–°–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ –∞–¥—Ä–µ—Å–∞–º:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8001
- **API Docs**: http://localhost:8001/docs
