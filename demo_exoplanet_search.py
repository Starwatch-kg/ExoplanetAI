#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(str(Path(__file__).parent / "src"))

import numpy as np
import matplotlib.pyplot as plt
from src.tess_data_loader import TESSDataLoader
from src.hybrid_transit_search import HybridTransitSearch
from src.representation_learning import SelfSupervisedRepresentationLearner, create_representation_dataset
from src.anomaly_ensemble import AnomalyEnsemble, create_anomaly_dataset
from src.results_exporter import ResultsExporter, ExoplanetCandidate

def create_synthetic_lightcurve_data():
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫—Ä–∏–≤—ã—Ö –±–ª–µ—Å–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    """
    print("–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∫—Ä–∏–≤—ã—Ö –±–ª–µ—Å–∫–∞...")
    
    np.random.seed(42)
    lightcurves = []
    tic_ids = []
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    num_stars = 10
    time_length = 2000
    time_range = 30  # –¥–Ω–µ–π
    
    for i in range(num_stars):
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã
        times = np.linspace(0, time_range, time_length)
        
        # –ë–∞–∑–æ–≤—ã–π –ø–æ—Ç–æ–∫ —Å —à—É–º–æ–º
        base_flux = 1.0 + 0.01 * np.random.randn(time_length)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –≤–∞—Ä–∏–∞—Ü–∏–π –∑–≤–µ–∑–¥—ã
        stellar_variation = 0.005 * np.sin(2 * np.pi * times / 5.0)  # 5-–¥–Ω–µ–≤–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        base_flux += stellar_variation
        
        # –°–ª—É—á–∞–π–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω–∑–∏—Ç—ã
        if np.random.rand() < 0.4:  # 40% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∏—Ç–∞
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω–∑–∏—Ç–∞
            period = np.random.uniform(3, 20)  # –ø–µ—Ä–∏–æ–¥ –≤ –¥–Ω—è—Ö
            depth = np.random.uniform(0.005, 0.03)  # –≥–ª—É–±–∏–Ω–∞ —Ç—Ä–∞–Ω–∑–∏—Ç–∞
            duration = np.random.uniform(0.1, 0.5)  # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –¥–Ω—è—Ö
            t0 = np.random.uniform(0, period)  # –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —Ç—Ä–∞–Ω–∑–∏—Ç–∞
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤
            for t in times:
                phase = (t - t0) % period
                if phase < duration or phase > (period - duration):
                    # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Ç—Ä–∞–Ω–∑–∏—Ç–∞
                    base_flux[int(t * time_length / time_range)] -= depth
        
        lightcurves.append((times, base_flux))
        tic_ids.append(f"TIC_{1000000 + i}")
    
    print(f"–°–æ–∑–¥–∞–Ω–æ {len(lightcurves)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∫—Ä–∏–≤—ã—Ö –±–ª–µ—Å–∫–∞")
    return lightcurves, tic_ids

def demonstrate_data_loading():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\n" + "="*50)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–•")
    print("="*50)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    loader = TESSDataLoader(cache_dir="demo_cache")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    lightcurves, tic_ids = create_synthetic_lightcurve_data()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
    for (times, fluxes), tic_id in zip(lightcurves, tic_ids):
        metadata = {
            'tic_id': tic_id,
            'ra': np.random.uniform(0, 360),
            'dec': np.random.uniform(-90, 90),
            'tmag': np.random.uniform(8, 15)
        }
        loader.save_lightcurve(times, fluxes, f"{tic_id}_lightcurve.csv", metadata)
    
    print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à –¥–ª—è {len(tic_ids)} –∑–≤–µ–∑–¥")
    return lightcurves, tic_ids

def demonstrate_hybrid_search(lightcurves, tic_ids):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤"""
    print("\n" + "="*50)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ì–ò–ë–†–ò–î–ù–û–ì–û –ü–û–ò–°–ö–ê –¢–†–ê–ù–ó–ò–¢–û–í")
    print("="*50)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    hybrid_search = HybridTransitSearch()
    
    all_candidates = []
    
    for i, ((times, fluxes), tic_id) in enumerate(zip(lightcurves[:3], tic_ids[:3])):
        print(f"–ê–Ω–∞–ª–∏–∑ {i+1}/3: {tic_id}")
        
        try:
            # –ü–æ–∏—Å–∫ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤
            results = hybrid_search.search_transits(times, fluxes)
            
            print(f"  –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results['candidates'])}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            for candidate_data in results['candidates']:
                candidate = ExoplanetCandidate(
                    tic_id=tic_id,
                    period=candidate_data['period'],
                    depth=candidate_data['depth'],
                    duration=candidate_data['duration'],
                    start_time=candidate_data['start_time'],
                    end_time=candidate_data['end_time'],
                    confidence=candidate_data['confidence'],
                    combined_score=candidate_data['combined_score'],
                    anomaly_probability=np.random.uniform(0.1, 0.8),  # –°–ª—É—á–∞–π–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                    star_info={
                        'ra': np.random.uniform(0, 360),
                        'dec': np.random.uniform(-90, 90),
                        'tmag': np.random.uniform(8, 15)
                    }
                )
                all_candidates.append(candidate)
                
        except Exception as e:
            print(f"  –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {tic_id}: {e}")
    
    print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(all_candidates)}")
    return all_candidates

def demonstrate_representation_learning(lightcurves):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π"""
    print("\n" + "="*50)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø –ü–†–ï–î–°–¢–ê–í–õ–ï–ù–ò–ô")
    print("="*50)
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤
    fluxes_list = [fluxes for _, fluxes in lightcurves]
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
    dataloader = create_representation_dataset(fluxes_list, batch_size=8)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–∞—Ç–µ–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
    learner = SelfSupervisedRepresentationLearner(
        input_length=2000,
        embedding_dim=64,  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –¥–µ–º–æ
        hidden_dim=128,
        num_layers=2
    )
    
    print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π...")
    
    # –û–±—É—á–µ–Ω–∏–µ (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –¥–ª—è –¥–µ–º–æ)
    loss_history = learner.train(dataloader, epochs=10, learning_rate=1e-3)
    
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è: {loss_history[-1]:.4f}")
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    embeddings, metadata = learner.encode_dataset(dataloader)
    print(f"–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π: {embeddings.shape}")
    
    return embeddings

def demonstrate_anomaly_detection(embeddings):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π"""
    print("\n" + "="*50)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –î–ï–¢–ï–ö–¶–ò–ò –ê–ù–û–ú–ê–õ–ò–ô")
    print("="*50)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π
    normal_data, anomaly_labels = create_anomaly_dataset(embeddings, anomaly_ratio=0.2)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è
    ensemble = AnomalyEnsemble(
        input_dim=embeddings.shape[1],
        latent_dim=16,
        hidden_dim=64
    )
    
    print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π...")
    
    # –û–±—É—á–µ–Ω–∏–µ (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –¥–ª—è –¥–µ–º–æ)
    import torch
    train_tensor = torch.tensor(normal_data, dtype=torch.float32)
    training_results = ensemble.train_ensemble(train_tensor, epochs=20)
    
    print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    test_scores = ensemble.predict_combined_anomaly_score(embeddings)
    print(f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏: {np.mean(test_scores):.3f}")
    
    return test_scores

def demonstrate_results_export(candidates):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("\n" + "="*50)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –≠–ö–°–ü–û–†–¢–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*50)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞
    exporter = ResultsExporter(output_dir="demo_results")
    
    if not candidates:
        print("–ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        return
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    csv_file = exporter.save_candidates_csv(candidates, "demo_candidates.csv")
    json_file = exporter.save_candidates_json(candidates, "demo_candidates.json")
    
    print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {csv_file}")
    print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON: {json_file}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    top_candidates = exporter.create_top_candidates_list(candidates, top_n=5)
    print(f"–¢–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
    for i, candidate in enumerate(top_candidates, 1):
        print(f"  {i}. {candidate.tic_id}: –ø–µ—Ä–∏–æ–¥={candidate.period:.3f}–¥, "
              f"–≥–ª—É–±–∏–Ω–∞={candidate.depth:.4f}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={candidate.confidence:.3f}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
    plot_files = exporter.create_visualization_plots(candidates, "demo_analysis")
    print(f"–°–æ–∑–¥–∞–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(plot_files)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_file = exporter._create_summary_report(candidates, "demo_report.txt")
    print(f"–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_file}")

def create_demo_visualization(lightcurves, candidates):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    print("\n" + "="*50)
    print("–°–û–ó–î–ê–ù–ò–ï –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–û–ù–ù–û–ô –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò")
    print("="*50)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Å –∫—Ä–∏–≤—ã–º–∏ –±–ª–µ—Å–∫–∞
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç', fontsize=16)
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –ü—Ä–∏–º–µ—Ä –∫—Ä–∏–≤–æ–π –±–ª–µ—Å–∫–∞
    times, fluxes = lightcurves[0]
    axes[0, 0].plot(times, fluxes, 'b-', alpha=0.7)
    axes[0, 0].set_title('–ü—Ä–∏–º–µ—Ä –∫—Ä–∏–≤–æ–π –±–ª–µ—Å–∫–∞')
    axes[0, 0].set_xlabel('–í—Ä–µ–º—è (–¥–Ω–∏)')
    axes[0, 0].set_ylabel('–ü–æ—Ç–æ–∫')
    axes[0, 0].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    if candidates:
        periods = [c.period for c in candidates]
        axes[0, 1].hist(periods, bins=10, alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–æ–≤')
        axes[0, 1].set_xlabel('–ü–µ—Ä–∏–æ–¥ (–¥–Ω–∏)')
        axes[0, 1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        axes[0, 1].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 3: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω
    if candidates:
        depths = [c.depth for c in candidates]
        axes[1, 0].hist(depths, bins=10, alpha=0.7, edgecolor='black')
        axes[1, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤')
        axes[1, 0].set_xlabel('–ì–ª—É–±–∏–Ω–∞')
        axes[1, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        axes[1, 0].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 4: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å vs –∫–∞—á–µ—Å—Ç–≤–æ
    if candidates:
        confidences = [c.confidence for c in candidates]
        quality_scores = [c.quality_score for c in candidates]
        scatter = axes[1, 1].scatter(confidences, quality_scores, 
                                    c=periods, cmap='viridis', alpha=0.7)
        axes[1, 1].set_title('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å vs –ö–∞—á–µ—Å—Ç–≤–æ')
        axes[1, 1].set_xlabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
        axes[1, 1].set_ylabel('–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞')
        axes[1, 1].grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=axes[1, 1], label='–ü–µ—Ä–∏–æ–¥ (–¥–Ω–∏)')
    
    plt.tight_layout()
    plt.savefig('demo_results/demo_visualization.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: demo_results/demo_visualization.png")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –ü–û–ò–°–ö–ê –≠–ö–ó–û–ü–õ–ê–ù–ï–¢")
    print("="*60)
    
    try:
        # 1. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        lightcurves, tic_ids = demonstrate_data_loading()
        
        # 2. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        candidates = demonstrate_hybrid_search(lightcurves, tic_ids)
        
        # 3. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
        embeddings = demonstrate_representation_learning(lightcurves)
        
        # 4. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π
        anomaly_scores = demonstrate_anomaly_detection(embeddings)
        
        # 5. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        demonstrate_results_export(candidates)
        
        # 6. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        create_demo_visualization(lightcurves, candidates)
        
        print("\n" + "="*60)
        print("‚úÖ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("="*60)
        print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–≤–µ–∑–¥: {len(lightcurves)}")
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: demo_results/")
        print(f"üìà –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ–∑–¥–∞–Ω—ã: demo_results/demo_visualization.png")
        
        if candidates:
            best_candidate = max(candidates, key=lambda x: x.quality_score)
            print(f"üèÜ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç: {best_candidate.tic_id}")
            print(f"   –ü–µ—Ä–∏–æ–¥: {best_candidate.period:.3f} –¥–Ω–µ–π")
            print(f"   –ì–ª—É–±–∏–Ω–∞: {best_candidate.depth:.4f}")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_candidate.confidence:.3f}")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
