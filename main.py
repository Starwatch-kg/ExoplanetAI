"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ —Å –∫–æ–Ω—Å–æ–ª—å–Ω—ã–º –º–µ–Ω—é –¥–ª—è –≤—ã–±–æ—Ä–∞
—Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π: –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –ø–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.
"""

import logging
import sys
import argparse
from pathlib import Path
from typing import List, Optional, Dict, Any
import json
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π
import numpy as np
from preprocess import TESSDataProcessor, create_synthetic_data
from model import train_model, ExoplanetAutoencoder, ExoplanetClassifier
from pipeline import search_exoplanets, ExoplanetPipeline
from visualize import visualize_results, ExoplanetVisualizer
from utils import calculate_metrics, create_train_test_split, validate_data_quality

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('exoplanet_search.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class ExoplanetSearchApp:
    """–û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
        self.data_processor = TESSDataProcessor()
        self.visualizer = ExoplanetVisualizer()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        self._create_directories()
        
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        directories = [
            'data/tess_cache',
            'models',
            'results',
            'results/plots',
            'results/candidates',
            'logs'
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def train_model(self, model_type: str = 'autoencoder',
                   epochs: int = 100,
                   batch_size: int = 32,
                   learning_rate: float = 1e-3,
                   use_synthetic: bool = True,
                   tic_ids: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç.
        
        Args:
            model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ ('autoencoder' –∏–ª–∏ 'classifier').
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è.
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
            learning_rate: –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.
            use_synthetic: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.
            tic_ids: –°–ø–∏—Å–æ–∫ TIC ID –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ).
            
        Returns:
            Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è.
        """
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–∏–ø–∞: {model_type}")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            if use_synthetic:
                logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                train_data, train_labels = create_synthetic_data(
                    num_samples=1000,
                    length=2000,
                    transit_fraction=0.3
                )
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
                X_train, X_val, y_train, y_val = create_train_test_split(
                    train_data, train_labels, test_size=0.2, random_state=42
                )
                
            else:
                if not tic_ids:
                    raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å TIC ID –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                
                logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(tic_ids)} –∑–≤–µ–∑–¥")
                lightcurves = self.data_processor.load_multiple_stars(tic_ids)
                
                if not lightcurves:
                    raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ TESS")
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                train_data, train_labels = self.data_processor.prepare_training_data(lightcurves)
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
                X_train, X_val, y_train, y_val = create_train_test_split(
                    train_data, train_labels, test_size=0.2, random_state=42
                )
            
            logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: train={len(X_train)}, val={len(X_val)}")
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path = f"models/{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
            
            model, history = train_model(
                model_type=model_type,
                train_data=X_train,
                train_labels=y_train if model_type == 'classifier' else None,
                val_data=X_val,
                val_labels=y_val if model_type == 'classifier' else None,
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                save_path=model_path
            )
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
            history_path = f"results/plots/training_history_{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            self.visualizer.plot_training_history(history, f"Training History - {model_type}", history_path)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            if model_type == 'classifier':
                import torch
                from model import ModelTrainer
                trainer = ModelTrainer()
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
                model.eval()
                with torch.no_grad():
                    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)
                    predictions = model(X_val_tensor)
                    predicted_labels = torch.argmax(predictions, dim=1).numpy()
                    predicted_scores = torch.softmax(predictions, dim=1)[:, 1].numpy()
                
                metrics = calculate_metrics(y_val, predicted_labels, predicted_scores)
            else:
                metrics = {'model_type': model_type}
            
            results = {
                'model_type': model_type,
                'model_path': model_path,
                'history': history,
                'metrics': metrics,
                'training_samples': len(X_train),
                'validation_samples': len(X_val),
                'epochs': epochs,
                'final_train_loss': history['train_loss'][-1] if 'train_loss' in history else 0,
                'final_val_loss': history['val_loss'][-1] if 'val_loss' in history else 0
            }
            
            logger.info(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            return results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def search_exoplanets(self, tic_ids: List[str],
                         sectors: Optional[List[int]] = None,
                         autoencoder_path: Optional[str] = None,
                         classifier_path: Optional[str] = None,
                         config: Optional[Dict] = None) -> Dict[str, Any]:
        """
        –ü–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç –¥–ª—è —Å–ø–∏—Å–∫–∞ –∑–≤–µ–∑–¥.
        
        Args:
            tic_ids: –°–ø–∏—Å–æ–∫ TIC ID –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
            sectors: –°–ø–∏—Å–æ–∫ —Å–µ–∫—Ç–æ—Ä–æ–≤ TESS.
            autoencoder_path: –ü—É—Ç—å –∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É.
            classifier_path: –ü—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É.
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
            
        Returns:
            Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞.
        """
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç –¥–ª—è {len(tic_ids)} –∑–≤–µ–∑–¥")
        
        try:
            # –ü–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç
            results = search_exoplanets(
                tic_ids=tic_ids,
                sectors=sectors,
                config=config,
                autoencoder_path=autoencoder_path,
                classifier_path=classifier_path
            )
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if results.get('candidates'):
                logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
                plot_files = visualize_results(results, create_all=True)
                results['plot_files'] = plot_files
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_path = f"results/search_report_{timestamp}.txt"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("–û–¢–ß–ï–¢ –û –ü–û–ò–°–ö–ï –≠–ö–ó–û–ü–õ–ê–ù–ï–¢\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"–î–∞—Ç–∞ –ø–æ–∏—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {results.get('processing_time', 'N/A')}\n")
                f.write(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ –∑–≤–µ–∑–¥—ã: {len(tic_ids)}\n")
                f.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–≤–µ–∑–¥: {results.get('loaded_stars', 0)}\n")
                f.write(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {results.get('total_candidates', 0)}\n\n")
                
                # –û—à–∏–±–∫–∏
                if results.get('errors'):
                    f.write("–û–®–ò–ë–ö–ò:\n")
                    for error in results['errors']:
                        f.write(f"  - {error}\n")
                    f.write("\n")
                
                # –¢–æ–ø –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
                candidates = results.get('candidates', [])
                if candidates:
                    f.write("–¢–û–ü-10 –ö–ê–ù–î–ò–î–ê–¢–û–í:\n")
                    f.write("-" * 80 + "\n")
                    f.write(f"{'‚Ññ':<3} {'TIC ID':<12} {'–ú–µ—Ç–æ–¥':<12} {'–ü–µ—Ä–∏–æ–¥':<8} {'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å':<12}\n")
                    f.write("-" * 80 + "\n")
                    
                    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    sorted_candidates = sorted(candidates, key=lambda x: x.get('confidence', 0), reverse=True)
                    
                    for i, candidate in enumerate(sorted_candidates[:10], 1):
                        f.write(f"{i:<3} {candidate['tic_id']:<12} "
                               f"{candidate['method']:<12} "
                               f"{candidate.get('period', 0):<8.3f} "
                               f"{candidate.get('confidence', 0):<12.3f}\n")
            
            results['report_path'] = report_path
            
            logger.info(f"–ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {results.get('total_candidates', 0)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
            logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
            return results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç: {e}")
            raise
    
    def test_pipeline(self, test_tic_ids: Optional[List[str]] = None,
                     use_synthetic: bool = True,
                     autoencoder_path: Optional[str] = None,
                     classifier_path: Optional[str] = None) -> Dict[str, Any]:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            test_tic_ids: –°–ø–∏—Å–æ–∫ TIC ID –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
            use_synthetic: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.
            autoencoder_path: –ü—É—Ç—å –∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É.
            classifier_path: –ü—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É.
            
        Returns:
            Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
        """
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞")
        
        try:
            if use_synthetic:
                logger.info("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∏—Ç–∞–º–∏
                test_data, test_labels = create_synthetic_data(
                    num_samples=200,
                    length=2000,
                    transit_fraction=0.4
                )
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö TIC ID
                test_tic_ids = [f"TIC_TEST_{i:06d}" for i in range(len(test_data))]
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                test_results = {
                    'test_samples': len(test_data),
                    'transit_samples': np.sum(test_labels),
                    'no_transit_samples': len(test_labels) - np.sum(test_labels),
                    'synthetic_data': True
                }
                
            else:
                if not test_tic_ids:
                    raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å TIC ID –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                
                logger.info(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(test_tic_ids)} –∑–≤–µ–∑–¥")
                test_results = {
                    'test_samples': len(test_tic_ids),
                    'synthetic_data': False
                }
            
            # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
            if use_synthetic:
                # –î–ª—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                pipeline_results = self._test_with_synthetic_data(test_data, test_labels, test_tic_ids)
            else:
                pipeline_results = self.search_exoplanets(
                    tic_ids=test_tic_ids,
                    autoencoder_path=autoencoder_path,
                    classifier_path=classifier_path
                )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            test_results.update(pipeline_results)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if use_synthetic and 'metrics' in pipeline_results:
                # –î–ª—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                test_results['performance_metrics'] = pipeline_results['metrics']
            elif use_synthetic and 'candidates' in pipeline_results:
                # Fallback –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                candidates = pipeline_results['candidates']
                
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç—ã, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ —É—Å–ø–µ—Ö–æ–º
                detected_transits = len(candidates)
                true_transits = np.sum(test_labels)
                
                precision = min(detected_transits / max(detected_transits, 1), 1.0)
                recall = min(detected_transits / max(true_transits, 1), 1.0)
                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
                
                test_results['performance_metrics'] = {
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1,
                    'detected_transits': detected_transits,
                    'true_transits': true_transits
                }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            test_report_path = f"results/test_report_{timestamp}.txt"
            
            with open(test_report_path, 'w', encoding='utf-8') as f:
                f.write("–û–¢–ß–ï–¢ –û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò –ü–ê–ô–ü–õ–ê–ô–ù–ê\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"–î–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {'–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ' if use_synthetic else '–†–µ–∞–ª—å–Ω—ã–µ'}\n")
                f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {test_results['test_samples']}\n")
                
                if use_synthetic:
                    f.write(f"–û–±—Ä–∞–∑—Ü—ã —Å —Ç—Ä–∞–Ω–∑–∏—Ç–∞–º–∏: {test_results['transit_samples']}\n")
                    f.write(f"–û–±—Ä–∞–∑—Ü—ã –±–µ–∑ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤: {test_results['no_transit_samples']}\n")
                
                f.write(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {test_results.get('total_candidates', 0)}\n")
                f.write(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {test_results.get('processing_time', 'N/A')}\n\n")
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if 'performance_metrics' in test_results:
                    metrics = test_results['performance_metrics']
                    f.write("–ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:\n")
                    f.write(f"  Precision: {metrics['precision']:.3f}\n")
                    f.write(f"  Recall: {metrics['recall']:.3f}\n")
                    f.write(f"  F1-Score: {metrics['f1_score']:.3f}\n")
                    f.write(f"  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤: {metrics['detected_transits']}\n")
                    f.write(f"  –ò—Å—Ç–∏–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤: {metrics['true_transits']}\n")
            
            test_results['test_report_path'] = test_report_path
            
            logger.info("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            logger.info(f"–û—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {test_report_path}")
            
            return test_results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
            raise
    
    def _test_with_synthetic_data(self, test_data: np.ndarray, test_labels: np.ndarray, test_tic_ids: List[str]) -> Dict[str, Any]:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ MAST.
        
        Args:
            test_data: –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—Ç–æ–≤—ã—Ö –∫—Ä–∏–≤—ã—Ö.
            test_labels: –ú–µ—Ç–∫–∏ —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤ (1 - –µ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∏—Ç, 0 - –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∏—Ç–∞).
            test_tic_ids: –°–ø–∏—Å–æ–∫ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö TIC ID.
            
        Returns:
            Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
        """
        logger.info("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            from pipeline import BoxLeastSquares
            from utils import calculate_metrics
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BLS –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
            bls_analyzer = BoxLeastSquares()
            
            candidates = []
            lightcurves = []
            all_scores = []
            all_predictions = []
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–≤–µ—Ç–æ–≤–æ–π –∫—Ä–∏–≤–æ–π
            for i, (data, label, tic_id) in enumerate(zip(test_data, test_labels, test_tic_ids)):
                logger.info(f"–ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞–∑—Ü–∞ {i+1}/{len(test_data)}: {tic_id}")
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã
                times = np.linspace(0, 30, len(data))
                
                # BLS –∞–Ω–∞–ª–∏–∑
                bls_results = bls_analyzer.compute_periodogram(times, data)
                
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                if bls_results and bls_results['best_power'] > 1000:  # –ü–æ—Ä–æ–≥ –¥–ª—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                    candidate = {
                        'tic_id': tic_id,
                        'period': bls_results['best_period'],
                        'depth': 0.01,  # –§–∏–∫—Ç–∏–≤–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
                        'confidence': min(bls_results['best_power'] / 10000, 1.0),
                        'method': 'BLS',
                        'bls_power': bls_results['best_power']
                    }
                    candidates.append(candidate)
                    all_predictions.append(1)
                else:
                    all_predictions.append(0)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–µ—Ç–æ–≤–æ–π –∫—Ä–∏–≤–æ–π
                lightcurves.append({
                    'tic_id': tic_id,
                    'times': times,
                    'fluxes': data,
                    'has_transit': bool(label)
                })
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö —Å–∫–æ—Ä–æ–≤
                score = bls_results['best_power'] if bls_results else 0
                all_scores.append(score)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            metrics = calculate_metrics(test_labels, np.array(all_predictions), np.array(all_scores))
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results = {
                'candidates': candidates,
                'lightcurves': lightcurves,
                'metrics': metrics,
                'total_stars': len(test_data),
                'detected_candidates': len(candidates),
                'true_transits': int(np.sum(test_labels)),
                'synthetic_test': True
            }
            
            logger.info(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: –Ω–∞–π–¥–µ–Ω–æ {len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ {int(np.sum(test_labels))} –∏—Å—Ç–∏–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤")
            return results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def visualize_results(self, results_path: str) -> Dict[str, str]:
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞.
        
        Args:
            results_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
            
        Returns:
            Dict[str, str]: –ü—É—Ç–∏ –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º –≥—Ä–∞—Ñ–∏–∫–∞–º.
        """
        logger.info(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞: {results_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            with open(results_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            plot_files = visualize_results(results, create_all=True)
            
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(plot_files)} –≥—Ä–∞—Ñ–∏–∫–æ–≤")
            return plot_files
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            raise


def display_menu():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é."""
    print("\n" + "="*60)
    print("üîç –°–ò–°–¢–ï–ú–ê –ü–û–ò–°–ö–ê –≠–ö–ó–û–ü–õ–ê–ù–ï–¢")
    print("="*60)
    print("1. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
    print("2. –ü–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç")
    print("3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞")
    print("4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("5. –í—ã—Ö–æ–¥")
    print("="*60)


def get_user_input(prompt: str, input_type: type = str, default: Any = None) -> Any:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–≤–æ–¥–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ç–∏–ø–∞.
    
    Args:
        prompt: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞.
        input_type: –û–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö.
        default: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        
    Returns:
        Any: –í–≤–µ–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.
    """
    while True:
        try:
            user_input = input(f"{prompt}: ").strip()
            
            if not user_input and default is not None:
                return default
            
            if input_type == bool:
                return user_input.lower() in ['y', 'yes', '–¥–∞', '1', 'true']
            elif input_type == int:
                return int(user_input)
            elif input_type == float:
                return float(user_input)
            elif input_type == list:
                return [item.strip() for item in user_input.split(',') if item.strip()]
            else:
                return user_input
                
        except ValueError:
            print(f"–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–∏–ø–∞ {input_type.__name__}")
        except KeyboardInterrupt:
            print("\n–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return None


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    parser = argparse.ArgumentParser(description='–°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç')
    parser.add_argument('--mode', choices=['interactive', 'train', 'search', 'test', 'visualize'],
                       default='interactive', help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--tic-ids', nargs='+', help='TIC ID –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
    parser.add_argument('--model-type', choices=['autoencoder', 'classifier'], 
                       default='autoencoder', help='–¢–∏–ø –º–æ–¥–µ–ª–∏')
    parser.add_argument('--epochs', type=int, default=100, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö')
    parser.add_argument('--autoencoder-path', help='–ü—É—Ç—å –∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É')
    parser.add_argument('--classifier-path', help='–ü—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É')
    parser.add_argument('--results-path', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    args = parser.parse_args()
    
    app = ExoplanetSearchApp()
    
    if args.mode == 'interactive':
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        while True:
            try:
                display_menu()
                choice = get_user_input("–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é (1-5)", int)
                
                if choice is None:
                    break
                
                if choice == 1:
                    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                    print("\nüìö –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
                    print("-" * 30)
                    
                    model_type = get_user_input("–¢–∏–ø –º–æ–¥–µ–ª–∏ (autoencoder/classifier)", 
                                               str, "autoencoder")
                    epochs = get_user_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö", int, 100)
                    batch_size = get_user_input("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", int, 32)
                    learning_rate = get_user_input("–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è", float, 1e-3)
                    use_synthetic = get_user_input("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ? (y/n)", 
                                                 bool, True)
                    
                    if not use_synthetic:
                        tic_ids_input = get_user_input("TIC ID (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", str)
                        tic_ids = [tid.strip() for tid in tic_ids_input.split(',')] if tic_ids_input else None
                    else:
                        tic_ids = None
                    
                    results = app.train_model(
                        model_type=model_type,
                        epochs=epochs,
                        batch_size=batch_size,
                        learning_rate=learning_rate,
                        use_synthetic=use_synthetic,
                        tic_ids=tic_ids
                    )
                    
                    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {results['model_path']}")
                    print(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è: {results['final_train_loss']:.4f}")
                    
                elif choice == 2:
                    # –ü–æ–∏—Å–∫ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç
                    print("\nüîç –ü–û–ò–°–ö –≠–ö–ó–û–ü–õ–ê–ù–ï–¢")
                    print("-" * 30)
                    
                    tic_ids_input = get_user_input("TIC ID (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", str)
                    if not tic_ids_input:
                        print("–û—à–∏–±–∫–∞: –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å TIC ID")
                        continue
                    
                    tic_ids = [tid.strip() for tid in tic_ids_input.split(',')]
                    
                    sectors_input = get_user_input("–°–µ–∫—Ç–æ—Ä—ã TESS (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, Enter –¥–ª—è –≤—Å–µ—Ö)", str)
                    sectors = None
                    if sectors_input:
                        sectors = [int(s.strip()) for s in sectors_input.split(',')]
                    
                    autoencoder_path = get_user_input("–ü—É—Ç—å –∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞)", str)
                    classifier_path = get_user_input("–ü—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞)", str)
                    
                    results = app.search_exoplanets(
                        tic_ids=tic_ids,
                        sectors=sectors,
                        autoencoder_path=autoencoder_path if autoencoder_path else None,
                        classifier_path=classifier_path if classifier_path else None
                    )
                    
                    print(f"\n‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                    print(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {results.get('total_candidates', 0)}")
                    print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {results.get('report_path', 'N/A')}")
                    
                elif choice == 3:
                    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
                    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ê–ô–ü–õ–ê–ô–ù–ê")
                    print("-" * 30)
                    
                    use_synthetic = get_user_input("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ? (y/n)", 
                                                 bool, True)
                    
                    test_tic_ids = None
                    if not use_synthetic:
                        tic_ids_input = get_user_input("TIC ID –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", str)
                        if tic_ids_input:
                            test_tic_ids = [tid.strip() for tid in tic_ids_input.split(',')]
                    
                    autoencoder_path = get_user_input("–ü—É—Ç—å –∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞)", str)
                    classifier_path = get_user_input("–ü—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞)", str)
                    
                    results = app.test_pipeline(
                        test_tic_ids=test_tic_ids,
                        use_synthetic=use_synthetic,
                        autoencoder_path=autoencoder_path if autoencoder_path else None,
                        classifier_path=classifier_path if classifier_path else None
                    )
                    
                    print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {results['test_samples']}")
                    print(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {results.get('total_candidates', 0)}")
                    
                    if 'performance_metrics' in results:
                        metrics = results['performance_metrics']
                        print(f"Precision: {metrics['precision']:.3f}")
                        print(f"Recall: {metrics['recall']:.3f}")
                        print(f"F1-Score: {metrics['f1_score']:.3f}")
                    
                    print(f"–û—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {results.get('test_report_path', 'N/A')}")
                    
                elif choice == 4:
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    print("\nüìä –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
                    print("-" * 30)
                    
                    results_path = get_user_input("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", str)
                    if not results_path:
                        print("–û—à–∏–±–∫–∞: –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        continue
                    
                    plot_files = app.visualize_results(results_path)
                    
                    print(f"\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                    print(f"–°–æ–∑–¥–∞–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(plot_files)}")
                    for plot_type, plot_path in plot_files.items():
                        print(f"  {plot_type}: {plot_path}")
                    
                elif choice == 5:
                    print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                
                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            except KeyboardInterrupt:
                print("\n\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
                input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
    
    else:
        # –†–µ–∂–∏–º –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        try:
            if args.mode == 'train':
                results = app.train_model(
                    model_type=args.model_type,
                    epochs=args.epochs,
                    tic_ids=args.tic_ids
                )
                print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ú–æ–¥–µ–ª—å: {results['model_path']}")
                
            elif args.mode == 'search':
                if not args.tic_ids:
                    print("–û—à–∏–±–∫–∞: –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --tic-ids")
                    return
                
                results = app.search_exoplanets(
                    tic_ids=args.tic_ids,
                    autoencoder_path=args.autoencoder_path,
                    classifier_path=args.classifier_path
                )
                print(f"–ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {results.get('total_candidates', 0)}")
                
            elif args.mode == 'test':
                results = app.test_pipeline(
                    test_tic_ids=args.tic_ids,
                    autoencoder_path=args.autoencoder_path,
                    classifier_path=args.classifier_path
                )
                print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±—Ä–∞–∑—Ü–æ–≤: {results['test_samples']}")
                
            elif args.mode == 'visualize':
                if not args.results_path:
                    print("–û—à–∏–±–∫–∞: –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --results-path")
                    return
                
                plot_files = app.visualize_results(args.results_path)
                print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ì—Ä–∞—Ñ–∏–∫–æ–≤: {len(plot_files)}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ä–µ–∂–∏–º–µ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏: {e}")
            print(f"–û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()